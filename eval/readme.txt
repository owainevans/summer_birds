# birdcast_eval.py
# Copyright (C) 2014 Oregon State University
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in
#    the documentation and/or other materials provided with the distribution.
# 3. Neither Oregon State University's name nor the names of other contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY OREGON STATE UNIVERSITY AND OTHER CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
# BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
# IN NO EVENT SHALL OREGON STATE UNIVERSITY OR OTHER CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
# STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
# EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# birdcast_eval.py -- evaluates Birdcast data set in relation to the ground truth

# version 0.70 (May 14, 2014)
=============================
- added check for input file/folders do not exist

# version 0.60 (May 14, 2014)
=============================
- Added 'eval_output_dir' (evaluation output directory where the evaluation report files generated by this program need to be stored) option to the command line
- Evaluation reports are redirected to 'eval_output_dir'
- Reorganized the command line parameters
  usage: birdcast_eval.py [-h] [--dataset DATASET] cps_output_dir ground_truth_dir eval_output_dir


# version 0.51 (May 11, 2014)
=============================
number.birds2 (flow prediction for tomorrow night) on the 19th day is ignored when computing the squared difference between the submitted values and the ground truth.

# version 0.5 (April 16, 2014)
==============================
Python versions supported:
--------------------------
This code has been tested using Python 2.7 and 3.4 on Windows/CentOS6.5
Required Python Packages: numpy, pandas

How to run:
-----------
usage: birdcast_eval.py [-h] [--dataset DATASET] cps_output_dir ground_truth_dir eval_output_dir

positional arguments:
  cps_output_dir    output directory containing the program output (for each dataset in a subdirectory)
                    to be evaluated against the ground truth
  ground_truth_dir  ground truth directory containing the ground truth for each dataset in a subdirectory
  eval_output_dir   evaluation output directory where the evaluation report
                    files generated by this program need to be stored

optional arguments:
  -h, --help         show this help message and exit
  --dataset DATASET  comma separated names of the datasets (d1,d2,d3) that need to be evaluated (default: all)

example run: python birdcast_eval.py data\output\ data\ground\ results

             This will run the evaluation on 'all' the datasets (d1-one bird, d2-1000 birds, d3-1000000 birds) where CPS outputs are stored in 'data\output', ground truth is stored in 'data\ground\', and finally the evaluation results will be stored in the 'results' directory 
  
example run: python birdcast_eval.py data\output\ data\ground\ results --dataset d2,d3

             This will run the evaluation on the datasets d2-1000 birds and d3-1000000 birds where CPS outputs are stored in 'data\output', ground truth is stored in 'data\ground\', and finally the evaluation results will be stored in the 'results directory

Directory Structure and Files:
------------------------------
The ground truth directory will have the following subdirectories and files. This ground truth (directory) is provided with this evaluation script.
  ground_truth_dir
			  - dataset1
				 - ground-parameters.csv
			  - dataset2
				 - 10x10x1000-reconstruction-ground.csv
				 - 10x10x1000-prediction-ground.csv
				 - ground-parameters.csv
			  - dataset3
				 - 10x10x1000000-reconstruction-ground.csv
				 - 10x10x1000000-prediction-ground.csv
				 - ground-parameters.csv


Program submitted by the teams will create the output directory. The output directory will have the following subdirectories and files.
  eval_output_dir
			  - dataset1
				 - estimated-parameters.csv
			  - dataset2
				 - 10x10x1000-train-reconstruction.csv
				 - 10x10x1000-test-prediction.csv
				 - estimated-parameters.csv
			  - dataset3
				 - 10x10x1000000-train-reconstruction.csv
				 - 10x10x1000000-test-prediction.csv
				 - estimated-parameters.csv


File Contents:
--------------
ground-parameters.csv
estimated-parameters.csv

Column names: b1,b2,b3,b4
# of rows: 1


10x10x1000-reconstruction-ground.csv
10x10x1000000-reconstruction-ground.csv
10x10x1000000-train-reconstruction.csv
10x10x1000000-train-reconstruction.csv

Column names: Year,Day,FromCell,ToCell,number.of.birds
# of rows: 1 row for each tuple (Year,Day,FromCell,ToCell)


10x10x1000-prediction-ground.csv
10x10x1000000-prediction-ground.csv
10x10x1000-test-prediction.csv
10x10x1000000-test-prediction.csv

Column names: Year,Day,FromCell,ToCell,number.birds,number.birds2
# of rows: 1 row for each tuple (Year,Day,FromCell,ToCell)


Evaluation Output:
------------------
This evaluation script generates a csv-report.

Column names: Dataset, Evaluation Metric, Value, (Value.Prediction.Tonight), (Value.Prediction.TomorrowNight)
Rows:
	  1 row for dataset1
	  3 rows for dataset2
	  3 rows for dataset3